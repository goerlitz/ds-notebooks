{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert CSV input file to parquet\n",
    "\n",
    "* Spark does not support out-of-the box data frame creation from CSV files.\n",
    "* Databricks' [spark-csv](https://github.com/databricks/spark-csv) provides such functionality but requires an extra library.\n",
    "\n",
    "\n",
    "The following code creates the data frame manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.Row\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val dataPath = \"../../data/expedia\"\n",
    "val dataName = \"train500k\"\n",
    "val fileName = s\"$dataPath/$dataName.csv.bz2\"\n",
    "\n",
    "val textRDD = sc.textFile(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get header and exclude it from input file\n",
    "\n",
    "Because all data is distributed we don't know which partition contains the first line. Hence, we need a filter to exclude it from further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val header = textRDD.first()\n",
    "val noHeaderRDD = textRDD.filter(line => line != header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data schema\n",
    "\n",
    "In order to handle NA values correctly define all columns as String. We will later convert each row into the appropriate type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val fields = header.split(',').map(StructField(_, StringType, true))\n",
    "val schema = StructType(fields)\n",
    "schema.foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val rowRDD = noHeaderRDD.map(_.split(',')).map(Row.fromSeq(_))\n",
    "val df = sqlContext.createDataFrame(rowRDD, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set correct column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val df2 = df.select(\n",
    "    df(\"date_time\").cast(TimestampType),\n",
    "    df(\"site_name\").cast(IntegerType),\n",
    "    df(\"posa_continent\").cast(IntegerType),\n",
    "    df(\"user_location_country\").cast(IntegerType),\n",
    "    df(\"user_location_region\").cast(IntegerType),\n",
    "    df(\"user_location_city\").cast(IntegerType),\n",
    "    df(\"orig_destination_distance\").cast(DoubleType),\n",
    "    df(\"user_id\").cast(IntegerType),\n",
    "    df(\"is_mobile\").cast(IntegerType),\n",
    "    df(\"is_package\").cast(IntegerType),\n",
    "    df(\"channel\").cast(IntegerType),\n",
    "    df(\"srch_ci\").cast(DateType),\n",
    "    df(\"srch_co\").cast(DateType),\n",
    "    df(\"srch_adults_cnt\").cast(IntegerType),\n",
    "    df(\"srch_children_cnt\").cast(IntegerType),\n",
    "    df(\"srch_rm_cnt\").cast(IntegerType),\n",
    "    df(\"srch_destination_id\").cast(IntegerType),\n",
    "    df(\"srch_destination_type_id\").cast(IntegerType),\n",
    "    df(\"is_booking\").cast(IntegerType),\n",
    "    df(\"cnt\").cast(IntegerType),\n",
    "    df(\"hotel_continent\").cast(IntegerType),\n",
    "    df(\"hotel_country\").cast(IntegerType),\n",
    "    df(\"hotel_market\").cast(IntegerType),\n",
    "    df(\"hotel_cluster\").cast(IntegerType)\n",
    "    )\n",
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.coalesce(1).write.save(s\"$dataPath/$dataName.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
